import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import davies_bouldin_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load Data
def load_data():
    customers = pd.read_csv('Customers.csv')
    transactions = pd.read_csv('Transactions.csv')
    return customers, transactions

# Perform Clustering
def perform_clustering(customers, transactions):
    # Aggregate transaction data for each customer
    customer_profiles = transactions.groupby('CustomerID').agg({
        'TotalValue': 'sum',
        'Quantity': 'sum'
    }).reset_index()

    # Merge with customer demographic data
    customer_profiles = customer_profiles.merge(customers[['CustomerID', 'Region']], on='CustomerID', how='left')

    # Encode categorical data
    customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'], drop_first=True)

    # Standardize features
    scaler = StandardScaler()
    features = customer_profiles.iloc[:, 1:].values  # Exclude CustomerID
    standardized_features = scaler.fit_transform(features)

    # Determine optimal number of clusters (optional)
    distortions = []
    for k in range(2, 11):
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(standardized_features)
        distortions.append(kmeans.inertia_)

    plt.figure(figsize=(8, 5))
    plt.plot(range(2, 11), distortions, marker='o')
    plt.title('Elbow Method for Optimal Clusters')
    plt.xlabel('Number of Clusters')
    plt.ylabel('Distortion')
    plt.show()

    # Apply K-Means Clustering
    optimal_clusters = 3  # Adjust based on the elbow method
    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
    customer_profiles['Cluster'] = kmeans.fit_predict(standardized_features)

    # Evaluate Clustering
    db_index = davies_bouldin_score(standardized_features, customer_profiles['Cluster'])
    print(f"Davies-Bouldin Index: {db_index}")

    # Visualize Clusters using PCA
    pca = PCA(n_components=2)
    reduced_features = pca.fit_transform(standardized_features)
    customer_profiles['PCA1'] = reduced_features[:, 0]
    customer_profiles['PCA2'] = reduced_features[:, 1]

    plt.figure(figsize=(10, 7))
    sns.scatterplot(
        x='PCA1', y='PCA2', hue='Cluster', data=customer_profiles, palette='viridis', s=100
    )
    plt.title('Customer Clusters')
    plt.show()

    # Save clustering results
    customer_profiles[['CustomerID', 'Cluster']].to_csv('FirstName_LastName_Clustering.csv', index=False)

# Main Function
def main():
    customers, transactions = load_data()
    perform_clustering(customers, transactions)
    print("Clustering results have been saved to 'FirstName_LastName_Clustering.csv'.")

if __name__ == "__main__":
    main()
