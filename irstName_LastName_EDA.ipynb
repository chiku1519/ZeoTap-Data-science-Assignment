# Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import davies_bouldin_score

# File URLs (use local file paths if downloaded)
customers_url = 'https://drive.google.com/file/d/1bu_--mo79VdUG9oin4ybfFGRUSXAe-WE/view?usp=sharing'
products_url = 'https://drive.google.com/file/d/1IKuDizVapw-hyktwfpoAoaGtHtTNHfd0/view?usp=sharing'
transactions_url = 'https://drive.google.com/file/d/1saEqdbBB-vuk2hxoAf4TzDEsykdKlzbF/view?usp=sharing'

# Load Data
def load_data():
    customers = pd.read_csv("customers.csv")
    products = pd.read_csv("Products.csv")
    transactions = pd.read_csv("Transactions.csv")
    return customers, products, transactions

# Exploratory Data Analysis
def perform_eda(customers, products, transactions):
    # Summary statistics
    print("Customers Summary:")
    print(customers.info(), customers.describe())

    print("Products Summary:")
    print(products.info(), products.describe())

    print("Transactions Summary:")
    print(transactions.info(), transactions.describe())

    # Visualizations
    plt.figure(figsize=(10, 6))
    sns.countplot(data=customers, x='Region', order=customers['Region'].value_counts().index)
    plt.title("Customer Count by Region")
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.barplot(data=products, x='Category', y='Price', ci=None, order=products.groupby('Category')['Price'].mean().sort_values(ascending=False).index)
    plt.title("Average Product Price by Category")
    plt.show()

# Lookalike Model
def build_lookalike_model(customers, transactions):
    customer_profiles = transactions.groupby('CustomerID').agg({
        'TotalValue': 'sum',
        'Quantity': 'sum'
    }).reset_index()

    customer_profiles = customer_profiles.merge(customers[['CustomerID', 'Region']], on='CustomerID', how='left')

    # Similarity Matrix
    similarity_matrix = cosine_similarity(customer_profiles.iloc[:, 1:])

    # Recommendations
    lookalike_results = {}
    for i, cust_id in enumerate(customer_profiles['CustomerID'][:20]):
        similar_indices = similarity_matrix[i].argsort()[-4:-1][::-1]  # Exclude self
        similar_customers = [(customer_profiles.iloc[j]['CustomerID'], similarity_matrix[i][j]) for j in similar_indices]
        lookalike_results[cust_id] = similar_customers

    lookalike_df = pd.DataFrame.from_dict(lookalike_results, orient='index', columns=['Customer1', 'Customer2', 'Customer3'])
    lookalike_df.to_csv('FirstName_LastName_Lookalike.csv', index=True)

# Customer Segmentation
def perform_clustering(customers, transactions):
    # Merge Data
    data = transactions.merge(customers, on='CustomerID', how='left')
    clustering_data = data.groupby('CustomerID').agg({
        'TotalValue': 'sum',
        'Quantity': 'sum'
    }).reset_index()

    # PCA for dimensionality reduction
    pca = PCA(2)
    clustering_data_reduced = pca.fit_transform(clustering_data.iloc[:, 1:])

    # K-Means Clustering
    kmeans = KMeans(n_clusters=3, random_state=42)
    clustering_data['Cluster'] = kmeans.fit_predict(clustering_data.iloc[:, 1:])

    # Evaluation
    db_index = davies_bouldin_score(clustering_data.iloc[:, 1:-1], clustering_data['Cluster'])
    print(f"Davies-Bouldin Index: {db_index}")

    # Visualization
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x=clustering_data_reduced[:, 0], y=clustering_data_reduced[:, 1], hue=clustering_data['Cluster'], palette='viridis')
    plt.title("Customer Clusters")
    plt.show()

# Main Function
def main():
    customers, products, transactions = load_data()
    
    # Task 1: EDA
    perform_eda(customers, products, transactions)

    # Task 2: Lookalike Model
    build_lookalike_model(customers, transactions)

    # Task 3: Clustering
    perform_clustering(customers, transactions)

if __name__ == "__main__":
    main()
